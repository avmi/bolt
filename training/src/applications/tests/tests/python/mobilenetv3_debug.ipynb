{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from pyraul.tools.dumping import print_torch_tensor, DumpMode, gen_cpp_dtVec\n",
    "\n",
    "# inplace=True means that x will be overwritten which reduces memory usage\n",
    "class hswish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out = x * F.relu6(x + 3, inplace=True) / 6\n",
    "        return out\n",
    "    \n",
    "# inplace=True means that x will be overwritten which reduces memory usage\n",
    "class hsigmoid(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out = F.relu6(x + 3, inplace=True) / 6\n",
    "        return out\n",
    "    \n",
    "class SeModule(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=4, bias=False):\n",
    "        super().__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), # Output 1x1xC (parameters adapts automatically)\n",
    "            nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1, stride=1, padding=0, bias=bias), # FC\n",
    "            nn.BatchNorm2d(in_channels // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1, stride=1, padding=0, bias=bias), # FC\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            hsigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    '''expand + depthwise + pointwise'''\n",
    "    def __init__(self, \n",
    "                 kernel_size, \n",
    "                 in_channels, \n",
    "                 expand_channels, \n",
    "                 out_channels, \n",
    "                 nolinear, \n",
    "                 semodule, \n",
    "                 stride,\n",
    "                 bias=False\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        self.se = semodule\n",
    "\n",
    "        # 1x1, NL\n",
    "        self.conv1 = nn.Conv2d(in_channels, expand_channels, kernel_size=1, stride=1, padding=0, bias=bias)\n",
    "        self.bn1 = nn.BatchNorm2d(expand_channels)\n",
    "        self.nolinear1 = nolinear\n",
    "        \n",
    "        # Dwise\n",
    "        self.conv2 = nn.Conv2d(expand_channels, expand_channels, kernel_size=kernel_size, stride=stride, padding=kernel_size//2, groups=expand_channels, bias=bias)\n",
    "        self.bn2 = nn.BatchNorm2d(expand_channels)\n",
    "        self.nolinear2 = nolinear\n",
    "        \n",
    "        # Linear\n",
    "        self.conv3 = nn.Conv2d(expand_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # For stride=2 no shorcut\n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        # For stride=1 blocks\n",
    "        if stride == 1 and in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=bias),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1x1, NL\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.nolinear1(out)\n",
    "        # Dwise\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.nolinear2(out)\n",
    "        # Lineaer\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.se != None:\n",
    "            out = self.se(out)\n",
    "        out = out + self.shortcut(x) if self.stride==1 else out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocks under debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(name, tensor):\n",
    "    if not hasattr(dump, \"history\"):\n",
    "        dump.history = {}\n",
    "    tensor = tensor.detach().cpu().numpy() \n",
    "    dump.history[name] = tensor\n",
    "    data = tensor[0].flatten()\n",
    "    with open(f'trace/{name}_w.txt', 'w') as f:\n",
    "        print(tensor.shape, file=f)\n",
    "        print(data.shape, file=f)\n",
    "        np.savetxt(f, data)\n",
    "    data = tensor.T[0].flatten()\n",
    "    with open(f'trace/{name}_h.txt', 'w') as f:\n",
    "        print(tensor.shape, file=f)\n",
    "        print(data.shape, file=f)\n",
    "        np.savetxt(f, data)\n",
    "            \n",
    "class MobileNetV3_Small(nn.Module):\n",
    "    def __init__(self, num_classes=1000, bias=False):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=bias)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.hs1 = hswish()\n",
    "        \n",
    "        self.layers.append((\"conv1\", self.conv1))\n",
    "        self.layers.append((\"bn1\", self.bn1))\n",
    "        self.layers.append((\"hs1\", self.hs1))\n",
    "\n",
    "        self.bneck = nn.Sequential(\n",
    "            Block(3, 16, 16, 16, nn.ReLU(inplace=True), SeModule(16, bias=bias), 2, bias=bias),\n",
    "            Block(3, 16, 72, 24, nn.ReLU(inplace=True), None, 2, bias=bias),\n",
    "            Block(3, 24, 88, 24, nn.ReLU(inplace=True), None, 1, bias=bias),\n",
    "            Block(5, 24, 96, 40, hswish(), SeModule(40, bias=bias), 2, bias=bias),\n",
    "            Block(5, 40, 240, 40, hswish(), SeModule(40, bias=bias), 1, bias=bias),\n",
    "            Block(5, 40, 240, 40, hswish(), SeModule(40, bias=bias), 1, bias=bias),\n",
    "            Block(5, 40, 120, 48, hswish(), SeModule(48, bias=bias), 1, bias=bias),\n",
    "            Block(5, 48, 144, 48, hswish(), SeModule(48, bias=bias), 1, bias=bias),\n",
    "            Block(5, 48, 288, 96, hswish(), SeModule(96, bias=bias), 2, bias=bias),\n",
    "            Block(5, 96, 576, 96, hswish(), SeModule(96, bias=bias), 1, bias=bias),\n",
    "            Block(5, 96, 576, 96, hswish(), SeModule(96, bias=bias), 1, bias=bias),\n",
    "        )\n",
    "        \n",
    "        self.layers.append((\"bneck\", self.bneck))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(96, 576, kernel_size=1, stride=1, padding=0, bias=bias)\n",
    "        self.bn2 = nn.BatchNorm2d(576)\n",
    "        self.hs2 = hswish()\n",
    "        \n",
    "        self.layers.append((\"conv2\", self.conv2))\n",
    "        self.layers.append((\"bn2\", self.bn2))\n",
    "        self.layers.append((\"hs2\", self.hs2))\n",
    "        \n",
    "        self.pool = lambda x: F.avg_pool2d(x, 7)\n",
    "        self.reshape = lambda x: x.view(x.size(0), -1)\n",
    "        \n",
    "        self.layers.append((\"pool\", self.pool))\n",
    "        self.layers.append((\"reshape\", self.reshape))\n",
    "        \n",
    "        self.linear3 = nn.Linear(576, 1024)\n",
    "        self.hs3 = hswish()\n",
    "        \n",
    "        self.layers.append((\"linear3\", self.linear3))\n",
    "        self.layers.append((\"hs3\", self.hs3))\n",
    "        \n",
    "        self.linear4 = nn.Linear(1024, num_classes)\n",
    "        self.layers.append((\"linear4\", self.linear4))\n",
    "        \n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        trace_tensor = x\n",
    "        for index, (name, layer) in enumerate(self.layers):\n",
    "            dump(f\"{index:02}_{name}_in\", trace_tensor.clone())\n",
    "            trace_tensor = layer(trace_tensor)\n",
    "            dump(f\"{index:02}_{name}_out\", trace_tensor.clone())\n",
    "        return trace_tensor\n",
    "            \n",
    "    \n",
    "from enum import Enum\n",
    "\n",
    "class ClassifierType(Enum):\n",
    "    Small=0\n",
    "    Large=1\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, model: ClassifierType, num_classes, bias=False):\n",
    "        super().__init__()\n",
    "        self.mobilenetv3 = None\n",
    "        if model == ClassifierType.Small:\n",
    "            self.mobilenetv3 = MobileNetV3_Small(num_classes, bias=bias)\n",
    "        if model == ClassifierType.Large:\n",
    "            self.mobilenetv3 = MobileNetV3_Large(num_classes, bias=bias)\n",
    "        assert self.mobilenetv3\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.mobilenetv3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from collections import namedtuple\n",
    "from typing import Callable, Optional, List\n",
    "from pyraul.tools.logging import get_fixedwide_str\n",
    "import numpy as np\n",
    "from pyraul.tools.seed import set_seed\n",
    "import torchvision.transforms as transforms\n",
    "from pyraul.tools.dataset import Dataset\n",
    "from pyraul.tools.dumping import dump_weights\n",
    "from pyraul.pipeline import accuracy\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, history: bool = False):\n",
    "        self.use_history = history\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        if self.use_history:\n",
    "            self.history=[]\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        if self.use_history:\n",
    "            self.history.append(val)\n",
    "            \n",
    "            \n",
    "def show_params(model):\n",
    "    print(\"====================================\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print_torch_tensor(name, param, slice_obj=slice(0,10), grad=True)\n",
    "#             if param.data is not None:\n",
    "#                 print(f\"{name}, {param.data.shape}\")\n",
    "#                 data = np.transpose(param.data)\n",
    "#                 data = data[0] if len(data.shape) > 1 else data\n",
    "#                 print([x.item() for x in data][:10])\n",
    "#             if param.grad is not None:\n",
    "#                 print(f\"grad of {name}, {param.grad.shape}\")\n",
    "#                 grad = np.transpose(param.grad)\n",
    "#                 grad = grad[0] if len(grad.shape) > 1 else grad\n",
    "#                 print([x.item() for x in grad][:10])\n",
    "    print(\"====================================\")\n",
    "        \n",
    "TrainStepResult = namedtuple(\"TrainStepResult\", [\"loss\", \"time_batch_load\", \"time_batch_full\"])\n",
    "\n",
    "def train_step(train_loader, \n",
    "               model, \n",
    "               criterion, \n",
    "               optimizer, \n",
    "               device, \n",
    "               print_freq=1,\n",
    "               verbose: bool = True,\n",
    "               loss_history: bool = False,\n",
    "               preprocessor: Optional[Callable] = None):\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter(history=loss_history)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    n = len(train_loader)\n",
    "    n_wide = len(str(n))\n",
    "    \n",
    "    cnt = 0\n",
    "    \n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        \n",
    "        if preprocessor:\n",
    "            input = preprocessor(input)\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.to(device)\n",
    "        input_var = input.to(device)\n",
    "        target_var = target\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.register_hook(lambda x: print(\"loss\", x))  \n",
    "        \n",
    "        loss.backward()\n",
    "        print_torch_tensor(\"loss\", loss, slice_obj=slice(0,10))\n",
    "#         show_params(model)\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "        \n",
    "        losses.update(loss.item(), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "    \n",
    "        if verbose and i % print_freq == 0:\n",
    "            print(f\"Step {get_fixedwide_str(str(i), n_wide)}/{n}\\t\"\n",
    "                  f\"Loss: {losses.val:.6f} ({losses.avg:.6f})\\t\"\n",
    "                  f\"Time.step: {batch_time.val:.3f} ({batch_time.avg:.3f})\\t\"\n",
    "                  f\"Time.load: {data_time.val:.3f} ({data_time.avg:.3f})\"\n",
    "                 )\n",
    "        cnt += 1\n",
    "        if cnt == 1:\n",
    "            break\n",
    "    return TrainStepResult(loss=losses, time_batch_load=data_time, time_batch_full=batch_time)\n",
    "\n",
    "# Delete me (from here)\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Callable, Optional\n",
    "\n",
    "def accuracy(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    preprocessor: Optional[Callable] = None,\n",
    "    device: str = \"cpu\",\n",
    "    squeeze_target: bool = False,\n",
    "    **kwargs,\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            if preprocessor:\n",
    "                data = preprocessor(data)\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            if squeeze_target:\n",
    "                labels = labels.squeeze()\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += outputs.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            break\n",
    "    return 100.0 * correct / total\n",
    "# Delete me (to here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading CIFAR10 dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "loss tensor(1., device='cuda:0')\n",
      "loss (torch.Size([])):\n",
      "['2.30252886']\n",
      "Step     0/12500\tLoss: 2.302529 (2.302529)\tTime.step: 3.034 (3.034)\tTime.load: 0.003 (0.003)\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"seed\": 0,\n",
    "    \"classes\": 10,\n",
    "    \"bias\": True,\n",
    "    \"batch_size\": 4,\n",
    "#     \"batch_size\": 50,\n",
    "    \"device\": \"cuda\",\n",
    "#     \"device\": \"cpu\",\n",
    "    \"epochs\": 1,\n",
    "    \"sgd\": {\"lr\": 0.05}\n",
    "}\n",
    "\n",
    "\n",
    "set_seed(config[\"seed\"])\n",
    "\n",
    "device = torch.device(config[\"device\"])\n",
    "model = Classifier(ClassifierType.Small, num_classes=config[\"classes\"], bias=config[\"bias\"])\n",
    "\n",
    "# dump_weights(model, \"init.txt\", mode=DumpMode.flatten_transpose)\n",
    "# dump_weights(model, \"init.txt\", mode=DumpMode.transpose_flatten, filter=\"linear\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "ds= Dataset(\"CIFAR10\",\n",
    "            train_transform=[transforms.Resize(224, interpolation=0), transforms.ToTensor()],\n",
    "            test_transform=[transforms.Resize(224, interpolation=0), transforms.ToTensor()],\n",
    "            **config)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config[\"sgd\"][\"lr\"])\n",
    "criterion = nn.NLLLoss(reduction=\"mean\")\n",
    "\n",
    "# accuracy_before = accuracy(\n",
    "#         model=model,\n",
    "#         dataloader=ds.test_loader,\n",
    "#         **config,\n",
    "# )\n",
    "\n",
    "\n",
    "# print(accuracy_before)\n",
    "\n",
    "\n",
    "# ####################\n",
    "# params = [(name, param) for name, param in model.named_parameters() if param.requires_grad]\n",
    "# print(params[-2][0])\n",
    "# debug_weights = params[-2][1].clone()\n",
    "# ####################\n",
    "\n",
    "\n",
    "loss, _, _ = train_step(\n",
    "                    ds.train_loader, \n",
    "                    model,\n",
    "                    criterion,\n",
    "                    optimizer,\n",
    "                    device,\n",
    "                    print_freq=100,\n",
    "                    verbose=True,\n",
    "                    loss_history=True\n",
    "                )\n",
    "\n",
    "# accuracy_after = accuracy(\n",
    "#     model=model,\n",
    "#     dataloader=ds.test_loader,\n",
    "#     **config,\n",
    "# )\n",
    "# print(accuracy_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "========================Before\n",
      "----\n",
      "weight\n",
      "torch.Size([16])\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "----\n",
      "bias\n",
      "torch.Size([16])\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "----\n",
      "running_mean\n",
      "torch.Size([16])\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "----\n",
      "running_var\n",
      "torch.Size([16])\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "----\n",
      "num_batches_tracked\n",
      "torch.Size([])\n",
      "0\n",
      "========================After\n",
      "----\n",
      "weight\n",
      "torch.Size([16])\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "----\n",
      "bias\n",
      "torch.Size([16])\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "----\n",
      "running_mean\n",
      "torch.Size([16])\n",
      "[0.0033524830359965563, 0.02775103785097599, -0.039781078696250916, -0.008996550925076008, 0.01896393671631813, 0.007416348904371262, -0.007661657873541117, 0.058414727449417114, -1.5173342944763135e-05, 0.03747266158461571, 0.008732253685593605, -0.03228681907057762, 0.027576124295592308, 0.03505025804042816, -0.015507864765822887, -0.0239370446652174]\n",
      "----\n",
      "running_var\n",
      "torch.Size([16])\n",
      "[0.9007676839828491, 0.9019309878349304, 0.9044464230537415, 0.9002496004104614, 0.9009020924568176, 0.9003293514251709, 0.9002734422683716, 0.9136167764663696, 0.900263249874115, 0.9050740599632263, 0.9005510807037354, 0.9026582837104797, 0.9044024348258972, 0.9042623043060303, 0.9005939960479736, 0.9027382731437683]\n",
      "----\n",
      "num_batches_tracked\n",
      "torch.Size([])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(dump.history[\"01_bn1_in\"])\n",
    "bn=nn.BatchNorm2d(16).train()\n",
    "print(bn)\n",
    "\n",
    "print(\"========================Before\")\n",
    "for k in bn.state_dict().keys():\n",
    "    tensor = bn.state_dict()[k]\n",
    "    print(\"----\", k, tensor.shape, [t.item() for t in tensor] if tensor.shape else tensor.item(), sep=\"\\n\")\n",
    "    \n",
    "y=bn(x)\n",
    "y_exp = dump.history[\"01_bn1_out\"]\n",
    "\n",
    "print(\"========================After\")\n",
    "for k in bn.state_dict().keys():\n",
    "    tensor = bn.state_dict()[k]\n",
    "    print(\"----\", k, tensor.shape, [t.item() for t in tensor] if tensor.shape else tensor.item(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 112, 112])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'x.txt', 'w') as f:\n",
    "    np.savetxt(f, x.flatten().T)\n",
    "with open(f'y.txt', 'w') as f:\n",
    "    np.savetxt(f, y_exp.flatten().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03352483 0.00767649\n",
      "0.27751040 0.01930936\n",
      "-0.39781079 0.04446352\n",
      "-0.08996550 0.00249623\n",
      "0.18963939 0.00902082\n",
      "0.07416350 0.00329357\n",
      "-0.07661659 0.00273430\n",
      "0.58414733 0.13616510\n",
      "-0.00015173 0.00263250\n",
      "0.37472659 0.05073946\n",
      "0.08732253 0.00551090\n",
      "-0.32286820 0.02658235\n",
      "0.27576125 0.04402352\n",
      "0.35050261 0.04262232\n",
      "-0.15507863 0.00594011\n",
      "-0.23937045 0.02738193\n"
     ]
    }
   ],
   "source": [
    "def bn_manual(tensor, momentum=0.1, epsilon=1e-5, unbiased=False):\n",
    "    result = tensor.clone()\n",
    "    channels = result.shape[1]\n",
    "    channel_mean_prev = [0.0]*channels\n",
    "    channel_var_prev = [1.0]*channels\n",
    "    shifted_input = result.clone()\n",
    "    \n",
    "    def mval(v, prev): return (1-momentum)*prev + momentum*v\n",
    "    \n",
    "    for c in range(channels):\n",
    "        channel_mean = result[:,c,:].mean()\n",
    "        channel_var = result[:,c,:].var(unbiased=unbiased)\n",
    "#         print(\n",
    "#             f\"{mval(channel_mean.item(), channel_mean_prev[c]):.8f}\",\n",
    "#             f\"{mval(channel_var.item(), channel_var_prev[c]):.8f}\"\n",
    "#             )\n",
    "        print(f\"{channel_mean:.8f}\", f\"{channel_var:.8f}\")\n",
    "#         channel_mean = mval(channel_mean.item(), channel_mean_prev[c])\n",
    "#         channel_var = mval(channel_var.item(), channel_var_prev[c])\n",
    "        \n",
    "        shifted = result[:,c,:]-channel_mean\n",
    "        normalized = shifted / (channel_var+epsilon)**(0.5)\n",
    "        result[:,c,:] = normalized\n",
    "        shifted_input[:,c,:] = shifted\n",
    "    return result, shifted_input\n",
    "        \n",
    "            \n",
    "# y_man_unbiased, _ = bn_manual(x, unbiased=True)\n",
    "# print(\"==\")\n",
    "y_man, y_man_shifted = bn_manual(x, unbiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y=-0.0145845\n",
      "e=-0.0145845\n",
      "m=-0.0145846\n",
      "x=0.0322462\n",
      "s=-0.0012787\n",
      "de=0.0\n",
      "dm=4.284083843231201e-08\n",
      "----\n",
      "y=-1.1202892\n",
      "e=-1.1202892\n",
      "m=-1.1202893\n",
      "x=-0.0646939\n",
      "s=-0.0982187\n",
      "de=0.0\n",
      "dm=1.1920928955078125e-07\n",
      "----\n",
      "y=-1.1202892\n",
      "e=-1.1202892\n",
      "m=-1.1202893\n",
      "x=-0.0646939\n",
      "s=-0.0982187\n",
      "de=0.0\n",
      "dm=1.1920928955078125e-07\n",
      "----\n",
      "y=-0.9679800\n",
      "e=-0.9679800\n",
      "m=-0.9679801\n",
      "x=-0.0513405\n",
      "s=-0.0848654\n",
      "de=0.0\n",
      "dm=1.7881393432617188e-07\n",
      "----\n",
      "y=-0.9414218\n",
      "e=-0.9414218\n",
      "m=-0.9414219\n",
      "x=-0.0490121\n",
      "s=-0.0825369\n",
      "de=0.0\n",
      "dm=5.960464477539063e-08\n",
      "----\n",
      "y=-0.9414218\n",
      "e=-0.9414218\n",
      "m=-0.9414219\n",
      "x=-0.0490121\n",
      "s=-0.0825369\n",
      "de=0.0\n",
      "dm=5.960464477539063e-08\n",
      "----\n",
      "y=-0.9414218\n",
      "e=-0.9414218\n",
      "m=-0.9414219\n",
      "x=-0.0490121\n",
      "s=-0.0825369\n",
      "de=0.0\n",
      "dm=5.960464477539063e-08\n",
      "----\n",
      "y=-1.0109986\n",
      "e=-1.0109986\n",
      "m=-1.0109987\n",
      "x=-0.0551121\n",
      "s=-0.0886369\n",
      "de=0.0\n",
      "dm=1.1920928955078125e-07\n",
      "----\n",
      "y=-1.1017083\n",
      "e=-1.1017083\n",
      "m=-1.1017083\n",
      "x=-0.0630648\n",
      "s=-0.0965897\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-1.1017083\n",
      "e=-1.1017083\n",
      "m=-1.1017083\n",
      "x=-0.0630648\n",
      "s=-0.0965897\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-1.1135340\n",
      "e=-1.1135340\n",
      "m=-1.1135341\n",
      "x=-0.0641016\n",
      "s=-0.0976264\n",
      "de=0.0\n",
      "dm=1.1920928955078125e-07\n",
      "----\n",
      "y=-1.4662091\n",
      "e=-1.4662091\n",
      "m=-1.4662092\n",
      "x=-0.0950216\n",
      "s=-0.1285464\n",
      "de=0.0\n",
      "dm=1.1920928955078125e-07\n",
      "----\n",
      "y=-1.4662091\n",
      "e=-1.4662091\n",
      "m=-1.4662092\n",
      "x=-0.0950216\n",
      "s=-0.1285464\n",
      "de=0.0\n",
      "dm=1.1920928955078125e-07\n",
      "----\n",
      "y=-1.4662091\n",
      "e=-1.4662091\n",
      "m=-1.4662092\n",
      "x=-0.0950216\n",
      "s=-0.1285464\n",
      "de=0.0\n",
      "dm=1.1920928955078125e-07\n",
      "----\n",
      "y=-1.5422812\n",
      "e=-1.5422812\n",
      "m=-1.5422814\n",
      "x=-0.1016910\n",
      "s=-0.1352158\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.0098276\n",
      "e=-2.0098276\n",
      "m=-2.0098281\n",
      "x=-0.1426820\n",
      "s=-0.1762069\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.0098276\n",
      "e=-2.0098276\n",
      "m=-2.0098281\n",
      "x=-0.1426820\n",
      "s=-0.1762069\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.1519814\n",
      "e=-2.1519814\n",
      "m=-2.1519816\n",
      "x=-0.1551450\n",
      "s=-0.1886699\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.3857002\n",
      "e=-2.3857002\n",
      "m=-2.3857007\n",
      "x=-0.1756358\n",
      "s=-0.2091606\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.3857002\n",
      "e=-2.3857002\n",
      "m=-2.3857007\n",
      "x=-0.1756358\n",
      "s=-0.2091606\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.3857002\n",
      "e=-2.3857002\n",
      "m=-2.3857007\n",
      "x=-0.1756358\n",
      "s=-0.2091606\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.3735940\n",
      "e=-2.3735940\n",
      "m=-2.3735945\n",
      "x=-0.1745744\n",
      "s=-0.2080992\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.7105684\n",
      "e=-2.7105684\n",
      "m=-2.7105689\n",
      "x=-0.2041178\n",
      "s=-0.2376427\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.7105684\n",
      "e=-2.7105684\n",
      "m=-2.7105689\n",
      "x=-0.2041178\n",
      "s=-0.2376427\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.7365108\n",
      "e=-2.7365108\n",
      "m=-2.7365110\n",
      "x=-0.2063923\n",
      "s=-0.2399171\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7696037\n",
      "e=-2.7696037\n",
      "m=-2.7696040\n",
      "x=-0.2092936\n",
      "s=-0.2428184\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7696037\n",
      "e=-2.7696037\n",
      "m=-2.7696040\n",
      "x=-0.2092936\n",
      "s=-0.2428184\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7696037\n",
      "e=-2.7696037\n",
      "m=-2.7696040\n",
      "x=-0.2092936\n",
      "s=-0.2428184\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6885140\n",
      "e=-2.6885140\n",
      "m=-2.6885140\n",
      "x=-0.2021842\n",
      "s=-0.2357091\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.7846451\n",
      "e=-2.7846451\n",
      "m=-2.7846456\n",
      "x=-0.2106123\n",
      "s=-0.2441372\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.7846451\n",
      "e=-2.7846451\n",
      "m=-2.7846456\n",
      "x=-0.2106123\n",
      "s=-0.2441372\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.8213181\n",
      "e=-2.8213181\n",
      "m=-2.8213181\n",
      "x=-0.2138275\n",
      "s=-0.2473524\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.7618268\n",
      "e=-2.7618268\n",
      "m=-2.7618272\n",
      "x=-0.2086118\n",
      "s=-0.2421366\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.7618268\n",
      "e=-2.7618268\n",
      "m=-2.7618272\n",
      "x=-0.2086118\n",
      "s=-0.2421366\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.7618268\n",
      "e=-2.7618268\n",
      "m=-2.7618272\n",
      "x=-0.2086118\n",
      "s=-0.2421366\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.8358274\n",
      "e=-2.8358274\n",
      "m=-2.8358276\n",
      "x=-0.2150996\n",
      "s=-0.2486244\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.5129931\n",
      "e=-2.5129931\n",
      "m=-2.5129931\n",
      "x=-0.1867959\n",
      "s=-0.2203207\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.5129931\n",
      "e=-2.5129931\n",
      "m=-2.5129931\n",
      "x=-0.1867959\n",
      "s=-0.2203207\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.4878616\n",
      "e=-2.4878616\n",
      "m=-2.4878616\n",
      "x=-0.1845925\n",
      "s=-0.2181174\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.3884184\n",
      "e=-2.3884184\n",
      "m=-2.3884187\n",
      "x=-0.1758741\n",
      "s=-0.2093989\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.3884184\n",
      "e=-2.3884184\n",
      "m=-2.3884187\n",
      "x=-0.1758741\n",
      "s=-0.2093989\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.3884184\n",
      "e=-2.3884184\n",
      "m=-2.3884187\n",
      "x=-0.1758741\n",
      "s=-0.2093989\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.3198779\n",
      "e=-2.3198779\n",
      "m=-2.3198781\n",
      "x=-0.1698650\n",
      "s=-0.2033898\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6243587\n",
      "e=-2.6243587\n",
      "m=-2.6243589\n",
      "x=-0.1965596\n",
      "s=-0.2300844\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6243587\n",
      "e=-2.6243587\n",
      "m=-2.6243589\n",
      "x=-0.1965596\n",
      "s=-0.2300844\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.5808501\n",
      "e=-2.5808501\n",
      "m=-2.5808506\n",
      "x=-0.1927451\n",
      "s=-0.2262699\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.6927476\n",
      "e=-2.6927476\n",
      "m=-2.6927478\n",
      "x=-0.2025554\n",
      "s=-0.2360803\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6927476\n",
      "e=-2.6927476\n",
      "m=-2.6927478\n",
      "x=-0.2025554\n",
      "s=-0.2360803\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6927476\n",
      "e=-2.6927476\n",
      "m=-2.6927478\n",
      "x=-0.2025554\n",
      "s=-0.2360803\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7309637\n",
      "e=-2.7309637\n",
      "m=-2.7309637\n",
      "x=-0.2059059\n",
      "s=-0.2394308\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.6024919\n",
      "e=-2.6024919\n",
      "m=-2.6024921\n",
      "x=-0.1946425\n",
      "s=-0.2281673\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6024919\n",
      "e=-2.6024919\n",
      "m=-2.6024921\n",
      "x=-0.1946425\n",
      "s=-0.2281673\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.5287817\n",
      "e=-2.5287817\n",
      "m=-2.5287819\n",
      "x=-0.1881801\n",
      "s=-0.2217049\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.4993439\n",
      "e=-2.4993439\n",
      "m=-2.4993441\n",
      "x=-0.1855992\n",
      "s=-0.2191240\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.4993439\n",
      "e=-2.4993439\n",
      "m=-2.4993441\n",
      "x=-0.1855992\n",
      "s=-0.2191240\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.4993439\n",
      "e=-2.4993439\n",
      "m=-2.4993441\n",
      "x=-0.1855992\n",
      "s=-0.2191240\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.4585202\n",
      "e=-2.4585202\n",
      "m=-2.4585202\n",
      "x=-0.1820201\n",
      "s=-0.2155449\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.6131723\n",
      "e=-2.6131723\n",
      "m=-2.6131725\n",
      "x=-0.1955789\n",
      "s=-0.2291037\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6131723\n",
      "e=-2.6131723\n",
      "m=-2.6131725\n",
      "x=-0.1955789\n",
      "s=-0.2291037\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6124275\n",
      "e=-2.6124275\n",
      "m=-2.6124277\n",
      "x=-0.1955135\n",
      "s=-0.2290384\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6065333\n",
      "e=-2.6065333\n",
      "m=-2.6065333\n",
      "x=-0.1949968\n",
      "s=-0.2285216\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.6065333\n",
      "e=-2.6065333\n",
      "m=-2.6065333\n",
      "x=-0.1949968\n",
      "s=-0.2285216\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.6065333\n",
      "e=-2.6065333\n",
      "m=-2.6065333\n",
      "x=-0.1949968\n",
      "s=-0.2285216\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.6911058\n",
      "e=-2.6911058\n",
      "m=-2.6911061\n",
      "x=-0.2024115\n",
      "s=-0.2359363\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.5157082\n",
      "e=-2.5157082\n",
      "m=-2.5157084\n",
      "x=-0.1870339\n",
      "s=-0.2205588\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.5157082\n",
      "e=-2.5157082\n",
      "m=-2.5157084\n",
      "x=-0.1870339\n",
      "s=-0.2205588\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6604371\n",
      "e=-2.6604371\n",
      "m=-2.6604373\n",
      "x=-0.1997227\n",
      "s=-0.2332475\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7335076\n",
      "e=-2.7335076\n",
      "m=-2.7335079\n",
      "x=-0.2061290\n",
      "s=-0.2396538\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7335076\n",
      "e=-2.7335076\n",
      "m=-2.7335079\n",
      "x=-0.2061290\n",
      "s=-0.2396538\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7335076\n",
      "e=-2.7335076\n",
      "m=-2.7335079\n",
      "x=-0.2061290\n",
      "s=-0.2396538\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7713406\n",
      "e=-2.7713406\n",
      "m=-2.7713406\n",
      "x=-0.2094459\n",
      "s=-0.2429707\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.7639716\n",
      "e=-2.7639716\n",
      "m=-2.7639718\n",
      "x=-0.2087998\n",
      "s=-0.2423247\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7639716\n",
      "e=-2.7639716\n",
      "m=-2.7639718\n",
      "x=-0.2087998\n",
      "s=-0.2423247\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6997228\n",
      "e=-2.6997228\n",
      "m=-2.6997232\n",
      "x=-0.2031670\n",
      "s=-0.2366918\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.6759295\n",
      "e=-2.6759295\n",
      "m=-2.6759300\n",
      "x=-0.2010809\n",
      "s=-0.2346058\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.6759295\n",
      "e=-2.6759295\n",
      "m=-2.6759300\n",
      "x=-0.2010809\n",
      "s=-0.2346058\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.6759295\n",
      "e=-2.6759295\n",
      "m=-2.6759300\n",
      "x=-0.2010809\n",
      "s=-0.2346058\n",
      "de=0.0\n",
      "dm=4.76837158203125e-07\n",
      "----\n",
      "y=-2.6238689\n",
      "e=-2.6238689\n",
      "m=-2.6238689\n",
      "x=-0.1965166\n",
      "s=-0.2300415\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.6551385\n",
      "e=-2.6551385\n",
      "m=-2.6551385\n",
      "x=-0.1992581\n",
      "s=-0.2327830\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.6551385\n",
      "e=-2.6551385\n",
      "m=-2.6551385\n",
      "x=-0.1992581\n",
      "s=-0.2327830\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.6827800\n",
      "e=-2.6827800\n",
      "m=-2.6827800\n",
      "x=-0.2016815\n",
      "s=-0.2352064\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.6938193\n",
      "e=-2.6938193\n",
      "m=-2.6938195\n",
      "x=-0.2026494\n",
      "s=-0.2361742\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6938193\n",
      "e=-2.6938193\n",
      "m=-2.6938195\n",
      "x=-0.2026494\n",
      "s=-0.2361742\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6938193\n",
      "e=-2.6938193\n",
      "m=-2.6938195\n",
      "x=-0.2026494\n",
      "s=-0.2361742\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6335549\n",
      "e=-2.6335549\n",
      "m=-2.6335552\n",
      "x=-0.1973659\n",
      "s=-0.2308907\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.8644705\n",
      "e=-2.8644705\n",
      "m=-2.8644707\n",
      "x=-0.2176108\n",
      "s=-0.2511356\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.8644705\n",
      "e=-2.8644705\n",
      "m=-2.8644707\n",
      "x=-0.2176108\n",
      "s=-0.2511356\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.9658225\n",
      "e=-2.9658225\n",
      "m=-2.9658227\n",
      "x=-0.2264966\n",
      "s=-0.2600214\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-3.0062993\n",
      "e=-3.0062993\n",
      "m=-3.0062995\n",
      "x=-0.2300453\n",
      "s=-0.2635702\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-3.0062993\n",
      "e=-3.0062993\n",
      "m=-3.0062995\n",
      "x=-0.2300453\n",
      "s=-0.2635702\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-3.0062993\n",
      "e=-3.0062993\n",
      "m=-3.0062995\n",
      "x=-0.2300453\n",
      "s=-0.2635702\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.9383163\n",
      "e=-2.9383163\n",
      "m=-2.9383163\n",
      "x=-0.2240851\n",
      "s=-0.2576099\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-3.0296230\n",
      "e=-3.0296230\n",
      "m=-3.0296233\n",
      "x=-0.2320902\n",
      "s=-0.2656150\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-3.0296230\n",
      "e=-3.0296230\n",
      "m=-3.0296233\n",
      "x=-0.2320902\n",
      "s=-0.2656150\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.9719620\n",
      "e=-2.9719620\n",
      "m=-2.9719622\n",
      "x=-0.2270349\n",
      "s=-0.2605597\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.8937974\n",
      "e=-2.8937974\n",
      "m=-2.8937974\n",
      "x=-0.2201820\n",
      "s=-0.2537068\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.8937974\n",
      "e=-2.8937974\n",
      "m=-2.8937974\n",
      "x=-0.2201820\n",
      "s=-0.2537068\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.8937974\n",
      "e=-2.8937974\n",
      "m=-2.8937974\n",
      "x=-0.2201820\n",
      "s=-0.2537068\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.8642764\n",
      "e=-2.8642764\n",
      "m=-2.8642764\n",
      "x=-0.2175938\n",
      "s=-0.2511186\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.8611197\n",
      "e=-2.8611197\n",
      "m=-2.8611200\n",
      "x=-0.2173170\n",
      "s=-0.2508419\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.8611197\n",
      "e=-2.8611197\n",
      "m=-2.8611200\n",
      "x=-0.2173170\n",
      "s=-0.2508419\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.8888273\n",
      "e=-2.8888273\n",
      "m=-2.8888273\n",
      "x=-0.2197462\n",
      "s=-0.2532711\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.8276212\n",
      "e=-2.8276212\n",
      "m=-2.8276215\n",
      "x=-0.2143802\n",
      "s=-0.2479050\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.8276212\n",
      "e=-2.8276212\n",
      "m=-2.8276215\n",
      "x=-0.2143802\n",
      "s=-0.2479050\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.8276212\n",
      "e=-2.8276212\n",
      "m=-2.8276215\n",
      "x=-0.2143802\n",
      "s=-0.2479050\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.8575258\n",
      "e=-2.8575258\n",
      "m=-2.8575258\n",
      "x=-0.2170020\n",
      "s=-0.2505268\n",
      "de=0.0\n",
      "dm=0.0\n",
      "----\n",
      "y=-2.7395794\n",
      "e=-2.7395794\n",
      "m=-2.7395797\n",
      "x=-0.2066613\n",
      "s=-0.2401861\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7395794\n",
      "e=-2.7395794\n",
      "m=-2.7395797\n",
      "x=-0.2066613\n",
      "s=-0.2401861\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.7418408\n",
      "e=-2.7418408\n",
      "m=-2.7418411\n",
      "x=-0.2068596\n",
      "s=-0.2403844\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6514723\n",
      "e=-2.6514723\n",
      "m=-2.6514726\n",
      "x=-0.1989367\n",
      "s=-0.2324615\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6514723\n",
      "e=-2.6514723\n",
      "m=-2.6514726\n",
      "x=-0.1989367\n",
      "s=-0.2324615\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n",
      "y=-2.6514723\n",
      "e=-2.6514723\n",
      "m=-2.6514726\n",
      "x=-0.1989367\n",
      "s=-0.2324615\n",
      "de=0.0\n",
      "dm=2.384185791015625e-07\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "i, j, k = 0, 0, 0\n",
    "for cmp_a, cmp_b, cmp_c, cmp_d, cmp_e in zip(y[i][j][k], y_exp[i][j][k], y_man[i][j][k], x[i][j][k], y_man_shifted[i][j][k]):\n",
    "    print(f\"y={cmp_a.item():.7f}\", \n",
    "          f\"e={cmp_b.item():.7f}\", \n",
    "          f\"m={cmp_c.item():.7f}\", \n",
    "          f\"x={cmp_d.item():.7f}\", \n",
    "          f\"s={cmp_e.item():.7f}\", \n",
    "          f\"de={abs(cmp_a - cmp_b).item()}\", \n",
    "          f\"dm={abs(cmp_a - cmp_c).item()}\", \n",
    "#           f\"du={abs(cmp_a - cmp_d).item()}\", \n",
    "          \"----\", sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
